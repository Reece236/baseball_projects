{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cbc333d",
   "metadata": {},
   "source": [
    "# Calculate Run Value from Pitch by Pitch Data\n",
    "\n",
    "## Purpose:\n",
    "### Prepare model to apply to synergy data to create similar matrix to the college baseball run environment, more specifically the CAA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f7acbe",
   "metadata": {},
   "source": [
    "## Deriving run values from pitch by pitch data from the 2022 regular season:\n",
    "### 1. Create a column containing the count-out-base state for each pitch.\n",
    "### 2. Split the data into individual half-innings.\n",
    "### 3. For each half-inning, create a new column that holds the difference in runs scored by the end of the half-inning compared to the beginning.\n",
    "### 4. Iterate through each pitch, adding the value in the 'runs_by_end' column to the existing run value for that state and increasing the count of times that state has occurred in a dictionary of states and run values. If the state is not already in the dictionary, add it with the value of 'runs_by_end' and a count of 1.\n",
    "### 5. For each state in the dictionary, divide the total run value by the number of times that state occurred to calculate the average runs scored by the end of the half-inning when that state is present.\n",
    "### 6. Create a new dictionary with the states as keys and the average runs scored as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b558a8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybaseball as pyb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca3467e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_half_inning_df(group):\n",
    "    # Create a new dataframe for the half-inning\n",
    "    half_inning_df = pd.DataFrame(group)\n",
    "        \n",
    "    return half_inning_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2d60e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_state_column(df, run_expectancy_dict):\n",
    "    df['run_expectancy'] = df['state'].map(run_expectancy_dict)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7183ff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_delta_run_expectancy(df):\n",
    "    # Shift the values in the 'run_expectancy' column down by one row\n",
    "    df['run_expectancy_shifted'] = df['run_expectancy'].shift(-1)\n",
    "    # Create a new column with the difference between the shifted 'run_expectancy' and the current 'run_expectancy'\n",
    "    df['delta_run_expectancy'] = df['run_expectancy_shifted'] - df['run_expectancy']\n",
    "    # For the last row in the dataframe, set the 'delta_run_expectancy' to 0 - 'run_expectancy'\n",
    "    df.loc[df.index[-1], 'delta_run_expectancy'] = 0 - df['run_expectancy'].iloc[-1]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beff4896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 186/186 [02:47<00:00,  1.11it/s]\n"
     ]
    }
   ],
   "source": [
    "reg_season = pyb.statcast(start_dt = '2021-04-01', end_dt = '2021-10-03')\n",
    "\n",
    "# drop pre-made run expectancy\n",
    "whole_season_df.drop(columns=['delta_run_expec'])\n",
    "\n",
    "# reverse order so dataframe is in chronological order\n",
    "reg_season = reg_season.iloc[::-1]\n",
    "\n",
    "# drop extra inning games and bottom of the 9th games\n",
    "reg_season = reg_season.loc[reg_season['inning'] <= 9]\n",
    "reg_season = reg_season.drop(reg_season[(reg_season['inning_topbot'] == 'Bottom') & \n",
    "                                        (reg_season['inning'] == 9)].index)\n",
    "\n",
    "# curently playerID or NaN, replace with 1 and 0\n",
    "for col in ['on_1b', 'on_2b', 'on_3b']:\n",
    "    # Replace NA values with 0\n",
    "    reg_season[col] = reg_season[col].fillna(0)\n",
    "    # Replace all other values with 1\n",
    "    reg_season[col] = reg_season[col].where(reg_season[col] == 0, 1)\n",
    "    \n",
    "# make a state column with the strike ball out base state\n",
    "reg_season['state'] = (\n",
    "    reg_season['strikes'].astype(str) + \n",
    "    reg_season['balls'].astype(str) + \n",
    "    reg_season['outs_when_up'].astype(str) + \n",
    "    reg_season['on_1b'].astype(int).astype(str) + \n",
    "    reg_season['on_2b'].astype(int).astype(str) + \n",
    "    reg_season['on_3b'].astype(int).astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa9144a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by game, inning, and top/bottom of inning\n",
    "half_innings = reg_season.groupby(['game_pk', 'inning', 'inning_topbot'])\n",
    "\n",
    "# Create an empty list to store the half-inning dataframes\n",
    "half_inning_dfs = []\n",
    "\n",
    "# Iterate over the groups in the half_innings object\n",
    "for name, group in half_innings:\n",
    "    # Apply the create_half_inning_df function to the group\n",
    "    half_inning_df = create_half_inning_df(group)\n",
    "    # Append the resulting dataframe to the half_inning_dfs list\n",
    "    half_inning_dfs.append(half_inning_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37ebd6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in half_inning_dfs:\n",
    "    # Select the last row of the dataframe\n",
    "    last_row = df.iloc[-1]\n",
    "\n",
    "    # Get the value of the 'column_name' column in the last row\n",
    "    last_row_value = last_row['post_bat_score']\n",
    "\n",
    "    # Assign the value of 'column_name' in the last row to the entire 'column_name' column\n",
    "    df['runs_by_end'] = last_row_value - df['bat_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab2e4fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# itterate over each pitch and record the runs by end for each state and ammount of times the state occured\n",
    "for df in half_inning_dfs:\n",
    "    for index, row in df.iterrows():\n",
    "        if row['state'] in globals():\n",
    "            globals().get(row['state'])[0] += row['runs_by_end']\n",
    "            globals().get(row['state'])[1] += 1\n",
    "        else:\n",
    "            globals()[row['state']] = [row['runs_by_end'], 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb55e12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = set(reg_season['state'])\n",
    "\n",
    "for state in states:\n",
    "    globals()[state] = globals()[state][0]/globals()[state][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32e3f01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_states_and_run_expectancy = []\n",
    "for state in states:\n",
    "    list_of_states_and_run_expectancy.append((state,globals()[state]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "429a80c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_expectancy_dict = dict(list_of_states_and_run_expectancy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c6ebb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_season['state'] = reg_season['state'].map(run_expectancy_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5a28cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the map() function to apply the map_state_column() function to each dataframe in the list\n",
    "half_inning_dfs = list(map(lambda x: map_state_column(x, run_expectancy_dict), half_inning_dfs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bd726ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the map() function to apply the calc_delta_run_expectancy() function to each dataframe in the list\n",
    "half_inning_dfs = list(map(calc_delta_run_expectancy, half_inning_dfs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22ab892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the dataframes in the list into a single dataframe\n",
    "whole_season_df = pd.concat(half_inning_dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c05098a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create runs_scored column for the total runs scored after an event\n",
    "whole_season_df['runs_scored'] = whole_season_df['post_bat_score'] - whole_season_df['bat_score']\n",
    "\n",
    "# fill empty events rows with the description\n",
    "whole_season_df['events'] = whole_season_df['events'].fillna(whole_season_df['description'])\n",
    "\n",
    "# add runs scored to delta run expectancy\n",
    "whole_season_df['delta_run_expectancy'] += whole_season_df['runs_scored']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a63dd71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            delta_run_expectancy\n",
      "events                                          \n",
      "ball                                    0.052429\n",
      "blocked_ball                            0.062863\n",
      "bunt_foul_tip                          -0.063155\n",
      "called_strike                          -0.049668\n",
      "catcher_interf                          0.401967\n",
      "caught_stealing_2b                     -0.222726\n",
      "caught_stealing_3b                     -0.387234\n",
      "caught_stealing_home                   -0.402878\n",
      "double                                  0.777701\n",
      "double_play                            -0.925319\n",
      "field_error                             0.447144\n",
      "field_out                              -0.239495\n",
      "fielders_choice                         0.677762\n",
      "fielders_choice_out                    -0.643154\n",
      "force_out                               -0.33077\n",
      "foul                                   -0.037426\n",
      "foul_bunt                              -0.061347\n",
      "foul_pitchout                          -0.054228\n",
      "foul_tip                               -0.060603\n",
      "game_advisory                          -0.659109\n",
      "grounded_into_double_play               -0.79259\n",
      "hit_by_pitch                            0.389987\n",
      "home_run                                1.372606\n",
      "missed_bunt                            -0.071307\n",
      "other_out                              -0.302465\n",
      "passed_ball                             0.575835\n",
      "pickoff_1b                             -0.330074\n",
      "pickoff_2b                              -0.33728\n",
      "pickoff_3b                             -0.520377\n",
      "pickoff_caught_stealing_2b             -0.101523\n",
      "pickoff_caught_stealing_3b             -0.446667\n",
      "pitchout                               -0.032472\n",
      "sac_bunt                               -0.123897\n",
      "sac_bunt_double_play                   -0.787961\n",
      "sac_fly                                -0.036336\n",
      "sac_fly_double_play                    -0.610474\n",
      "single                                  0.467832\n",
      "stolen_base_2b                         -0.163199\n",
      "strikeout                               -0.22372\n",
      "strikeout_double_play                  -0.730514\n",
      "swinging_strike                        -0.058646\n",
      "swinging_strike_blocked                -0.084313\n",
      "triple                                  1.053631\n",
      "triple_play                            -1.701932\n",
      "walk                                    0.221455\n",
      "wild_pitch                              0.409311\n"
     ]
    }
   ],
   "source": [
    "# print average run expectancy for each event\n",
    "print(whole_season_df[['events','delta_run_expectancy']].groupby('events').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ca2efe",
   "metadata": {},
   "source": [
    "# Using the calculated Run Value, create xRun Value with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "105c56a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0298b9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost(data, features, y_value, optimal_params = None):\n",
    "    \n",
    "    # define x and y data\n",
    "    x = data[features]\n",
    "    y = data[y_value]\n",
    "    \n",
    "    if optimal_params == None:\n",
    "\n",
    "        # seperate test and training sets\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=6)\n",
    "\n",
    "        # create list to keep scores\n",
    "        score_list = []\n",
    "        optimal_params = {}\n",
    "\n",
    "        # grid search to find optimal hyperparameters\n",
    "        for max_depth in range(1, 25):\n",
    "            for learning_rate in [0.001, 0.01, 0.1, 1]:\n",
    "                for n_estimators in [100, 250, 500, 1000]:\n",
    "                    model = XGBRegressor(max_depth=max_depth, learning_rate=learning_rate, n_estimators=n_estimators)\n",
    "                    model.fit(x_train, y_train)\n",
    "                    y_pred_test = model.predict(x_test)\n",
    "                    score = model.score(x_test, y_test)\n",
    "                    score_list.append(score)\n",
    "                    params = (max_depth, learning_rate, n_estimators)\n",
    "                    optimal_params[score] = params\n",
    "                    print(optimal_params, score)\n",
    "\n",
    "        optimal_score = max(score_list)\n",
    "        optimal_params = optimal_params[optimal_score]\n",
    "    \n",
    "    # intialize regressor model with optimal hyperparameters and fit data\n",
    "    model = XGBRegressor(max_depth=optimal_params[0], learning_rate=optimal_params[1], n_estimators=optimal_params[2])\n",
    "    model.fit(x, y)\n",
    "\n",
    "    # return the model\n",
    "    return model, optimal_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ae4eede",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_df = whole_season_df.loc[whole_season_df['pitch_type'] == 'FF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f613dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['release_speed', 'release_pos_x', 'release_pos_z', 'pfx_x', 'pfx_z', \n",
    "            'plate_x', 'plate_z', 'vx0', 'vy0', 'vz0', 'ax', 'ay', 'az', 'effective_speed',\n",
    "            'release_spin_rate', 'release_extension', 'release_pos_y', 'spin_axis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb39a4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal_params comes out to (3, 0.01, 1000)\n",
    "\n",
    "model, optimal_params = xgboost(ff_df, features, 'delta_run_expectancy', optimal_params = (3, 0.01, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed4e000f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reececalvin/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1667: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n"
     ]
    }
   ],
   "source": [
    "ff_df.loc[:,'xrun_value'] = model.predict(ff_df.loc[:,features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea116509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025281763288097836"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = ff_df['delta_run_expectancy'].astype(float)\n",
    "y_pred = ff_df['xrun_value'].astype(float)\n",
    "\n",
    "score = metrics.r2_score(y_true, y_pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c185880",
   "metadata": {},
   "source": [
    "###### Evidently this model needs a lot of work."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
